{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python375jvsc74a57bd057baa5815c940fdaff4d14510622de9616cae602444507ba5d0b6727c008cbd6",
   "display_name": "Python 3.7.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "57baa5815c940fdaff4d14510622de9616cae602444507ba5d0b6727c008cbd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from io import StringIO \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zadanie 5\n",
    "import numpy as np\n",
    "from numpy.core.fromnumeric import shape\n",
    "\n",
    "def dmtest(e1, e2, h=1, lossf='AE'):\n",
    "    e1 = np.array(e1)\n",
    "    e2 = np.array(e2)\n",
    "    T = len(e1)\n",
    "    if lossf == 'AE':\n",
    "        d = np.abs(e1) - np.abs(e2)\n",
    "    else: # lossf == 'SE'\n",
    "        d = e1**2 - e2**2\n",
    "    dMean = np.mean(d)\n",
    "    gamma0 = np.var(d)\n",
    "    if h > 1:\n",
    "        raise NotImplementedError()\n",
    "    else:\n",
    "        varD = gamma0\n",
    "\n",
    "    DM = dMean / np.sqrt((1 / T) * varD)\n",
    "    return DM\n",
    "\n",
    "\n",
    "\n",
    "def forecast_arx(DATA,loc_index,save_beta,hour=0,week_day=0):\n",
    "    # DATA: 8-column matrix (date, hour, price, load forecast, Sat, Sun, Mon dummy, p_min)\n",
    "    # Select data to be used\n",
    "    # print(DATA[-1, :])\n",
    "    price = DATA[:-1, 2]             # For day d (d-1, ...)\n",
    "    price_min = DATA[:-1, 11]         # For day d\n",
    "    Dummies = DATA[1:, 4:11]          # Dummies for day d+1\n",
    "    loadr = DATA[1:, 3]              # Load for day d+1\n",
    "\n",
    "    # Take logarithms\n",
    "    price = np.log(price)\n",
    "    mc = np.mean(price)\n",
    "    price -= mc                      # Remove mean(price)\n",
    "    price_min = np.log(price_min)\n",
    "    price_min -= np.mean(price_min)  # Remove mean(price)\n",
    "    loadr = np.log(loadr)\n",
    "\n",
    "    # Calibrate the ARX model\n",
    "    y = price[7:]                    # For day d, d-1, ...\n",
    "    # Define explanatory variables for calibration\n",
    "    # without intercept\n",
    "    X = np.vstack([price[6:-1], price[5:-2], price[:-7], price_min[6:-1],\n",
    "                   loadr[6:-1], Dummies[6:-1, 0], Dummies[6:-1, 1], Dummies[6:-1, 2], Dummies[6:-1, 3], Dummies[6:-1, 4], Dummies[6:-1, 5], Dummies[6:-1, 6]]).T\n",
    "    # with intercept\n",
    "    # X = np.vstack([np.ones(len(y)), price[6:-1], price[5:-2], price[:-7], price_min[6:-1],\n",
    "    #                loadr[6:-1], Dummies[6:-1, 0], Dummies[6:-1, 1], Dummies[6:-1, 2]]).T\n",
    "    # Define explanatory variables for day d+1\n",
    "    # without intercept\n",
    "    X_fut = np.hstack([price[-1], price[-2], price[-7], price_min[-1],\n",
    "                    loadr[-1], Dummies[-1, 0], Dummies[-1, 1], Dummies[-1, 2], Dummies[-1, 3], Dummies[-1, 4], Dummies[-1, 5], Dummies[-1, 6]])\n",
    "    # with intercept\n",
    "    # X_fut = np.hstack([[1], price[-1], price[-2], price[-7], price_min[-1],\n",
    "    #                    loadr[-1], Dummies[-1, 0], Dummies[-1, 1], Dummies[-1, 2]])\n",
    "    # if index > 360 pomijać beta = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "    if(loc_index < 360):\n",
    "        loc_index = loc_index + 1\n",
    "        beta = np.linalg.lstsq(X, y, rcond=None)[0]  # Estimate the ARX model\n",
    "        save_beta[hour,:] = beta\n",
    "        prog = np.dot(beta, X_fut)                   # Compute a step-ahead forecast\n",
    "        return [np.exp(prog + mc),loc_index,save_beta]                     # Convert to price level\n",
    "    else:\n",
    "        prog = np.dot(save_beta[hour,:], X_fut)                   # Compute a step-ahead forecast\n",
    "        return [np.exp(prog + mc),loc_index,save_beta]                     # Convert to price level\n",
    "\n",
    "\n",
    "def forecast_narx(DATA):\n",
    "    import keras\n",
    "    from keras.layers import Input, Dense\n",
    "    from keras.models import Model\n",
    "    from keras.callbacks import EarlyStopping\n",
    "    # DATA: 8-column matrix (date, hour, price, load forecast, Sat, Sun, Mon dummy, p_min)\n",
    "    # Select data to be used\n",
    "    # print(DATA[-1, :])\n",
    "    price = DATA[:-1, 2]             # For day d (d-1, ...)\n",
    "    price_min = DATA[:-1, 11]         # For day d\n",
    "    Dummies = DATA[1:, 4:10]          # Dummies for day d+1\n",
    "    loadr = DATA[1:, 3]              # Load for day d+1\n",
    "\n",
    "    # Take logarithms\n",
    "    price = np.log(price)\n",
    "    mc = np.mean(price)\n",
    "    price -= mc                      # Remove mean(price)\n",
    "    price_min = np.log(price_min)\n",
    "    price_min -= np.mean(price_min)  # Remove mean(price)\n",
    "    loadr = np.log(loadr)\n",
    "\n",
    "    # Calibrate the ARX model\n",
    "    y = price[7:]                    # For day d, d-1, ...\n",
    "    # Define explanatory variables for calibration\n",
    "    '''\n",
    "    dodać pozostałe Dummies 0-6\n",
    "    '''\n",
    "    print(shape(Dummies))\n",
    "\n",
    "    X = np.vstack([price[6:-1], price[5:-2], price[:-7], price_min[6:-1],\n",
    "                   loadr[6:-1], Dummies[6:-1, 0], Dummies[6:-1, 1], Dummies[6:-1, 2], Dummies[6:-1, 3], Dummies[6:-1, 4], Dummies[6:-1, 5], Dummies[6:-1, 6]]).T\n",
    "    # Define explanatory variables for day d+1\n",
    "    X_fut = np.hstack([price[-1], price[-2], price[-7], price_min[-1],\n",
    "                       loadr[-1], Dummies[-1, 0], Dummies[-1, 1], Dummies[-1, 2], Dummies[-1, 3], Dummies[-1, 4], Dummies[-1, 5], Dummies[-1, 6]])\n",
    "\n",
    "    # Define Neural Network model\n",
    "    inputs = Input(shape=(X.shape[1], ))                  # Input layer\n",
    "    hidden = Dense(units=20, activation='sigmoid')(inputs)# Hidden layer (20 neurons)\n",
    "    outputs = Dense(units=1, activation='linear')(hidden) # Output layer\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    # callbacks = [EarlyStopping(patience=20, restore_best_weights=True)]\n",
    "    callbacks = []\n",
    "    model.compile(loss='MAE', optimizer='ADAM')           # Compile model\n",
    "    model.fit(X, y, batch_size=64, epochs=500, verbose=0, # Fit to data\n",
    "              validation_split=.0, shuffle=False, callbacks=callbacks)\n",
    "    prog = model.predict(np.array(X_fut, ndmin=2))        # Compute a step-ahead forecast\n",
    "\n",
    "    return np.exp(prog + mc)                     # Convert to price level\n",
    "\n",
    "def forecast_naive(DATA):\n",
    "    if np.sum(DATA[-1, 4:7]) > 0:\n",
    "        return DATA[-8, 2]\n",
    "    return DATA[-2, 2]\n",
    "\n",
    "import numpy as np\n",
    "from calendar import weekday\n",
    "from time import time as t\n",
    "\n",
    "def task(argtup):\n",
    "    '''Helper function for multi-core NARX'''\n",
    "    data, startd, endd, j, hour = argtup\n",
    "    data_h = data[hour::24, :]\n",
    "    ts = t()\n",
    "    task_output = forecast_narx(data_h[startd + j:endd + j + 1, :])\n",
    "    print(f'{j}\\t{hour}\\t{t() - ts}')\n",
    "    return task_output \n",
    "\n",
    "def epf_arx(data, Ndays, startd, endd, forecast_type='naive',loc_index=0,save_beta=0):\n",
    "    if forecast_type.lower() == 'narx':      # forecst_narx imports additional libraries, importing\n",
    "        print(\":)\")\n",
    "        # from forecast import forecast_narx   # here ensures that they are not needed for ARX or naive\n",
    "    elif forecast_type.lower() == 'narx_mc': # multi-core variant\n",
    "        from multiprocessing import Pool\n",
    "    # DATA:   4-column matrix (date, hour, price, load forecast)\n",
    "    # RESULT: 4-column matrix (date, hour, price, forecasted price)\n",
    "    first_day = str(int(data[0, 0]))\n",
    "    first_day = (int(e) for e in (first_day[:4], first_day[4:6], first_day[6:]))\n",
    "    i = weekday(*first_day) # Weekday of starting day: 0 - Monday, ..., 6 - Sunday\n",
    "    N = len(data) // 24\n",
    "    data = np.hstack([data, np.zeros((N*24, 9))]) # Append 'data' matrix with daily dummies & p_min\n",
    "    for j in range(N):\n",
    "\n",
    "        if i % 7 == 5:\n",
    "            data[24*j:24*(j+1), 4] = 1 # Saturday dummy in 5th (index 4) column\n",
    "        elif i % 7 == 6:\n",
    "            data[24*j:24*(j+1), 5] = 1 # Sunday dummy in 6th column\n",
    "        elif i % 7 == 0:\n",
    "            data[24*j:24*(j+1), 6] = 1 # Monday dummy in 7th column\n",
    "        elif i % 7 == 1:\n",
    "            data[24*j:24*(j+1), 7] = 1 # wtorek\n",
    "        elif i % 7 == 2:\n",
    "            data[24*j:24*(j+1), 8] = 1 # sroda\n",
    "        elif i % 7 == 3:\n",
    "            data[24*j:24*(j+1), 9] = 1 # czwartek\n",
    "        elif i % 7 == 4:\n",
    "            data[24*j:24*(j+1), 10] = 1 # piatek\n",
    "\n",
    "            '''\n",
    "        # Dummies dla pozostałych dni\n",
    "        '''\n",
    "        i += 1\n",
    "        data[24*j:24*(j+1), 11] = np.min(data[24*j:24*(j+1), 2]) # p_min in 8th column\n",
    "        data[24*j:24*(j+1), 12] = data[24*j:24*(j+1), 2] # p_min in 8th column\n",
    "        '''\n",
    "        8 kolumna cena z godziny 24\n",
    "        '''\n",
    "    result = np.zeros((Ndays * 24, 4)) # Initialize `result` matrix\n",
    "    result[:, :3] = data[endd*24:(endd + Ndays) * 24, :3]\n",
    "    if forecast_type.lower() == 'narx_mc': # multi-core invocation of NARX model\n",
    "        argtups = [(data, startd, endd, j, h) for j in range(Ndays) for h in range(24)]\n",
    "        with Pool() as pool:   # Pool(N) uses N simultaneous processes\n",
    "            res = pool.map(task, argtups)\n",
    "        result[:, 3] = res\n",
    "        return result\n",
    "    # n_week_day = weekday(*first_day)\n",
    "    for j in range(Ndays):     # For all days ...\n",
    "        for hour in range(24): # ... compute 1-day ahead forecasts for each hour\n",
    "            data_h = data[hour::24, :]\n",
    "            # Compute forecasts for the hour\n",
    "            if forecast_type.lower() == 'narx':\n",
    "                ts = t()\n",
    "                result[j * 24 + hour, 3] = forecast_narx(data_h[startd + j:endd + j + 1, :])\n",
    "                print(f'{j}\\t{hour}\\t{t() - ts}')\n",
    "            elif forecast_type.lower() == 'arx':\n",
    "                result[j * 24 + hour, 3] = forecast_arx(data_h[startd + j :endd +j + 1, :],loc_index,save_beta,hour)[0]\n",
    "                '''\n",
    "                # Beta powinna być macierza 24x12\n",
    "                ''' \n",
    "                loc_index = forecast_arx(data_h[startd + j :endd +j + 1, :],loc_index,save_beta)[1]\n",
    "                save_beta[hour,:] = forecast_arx(data_h[startd + j :endd +j + 1, :],loc_index,save_beta)[2][hour,:]\n",
    "\n",
    "            elif forecast_type.lower() == 'naive':\n",
    "                result[j * 24 + hour, 3] = forecast_naive(data_h[startd + j:endd + j + 1, :])\n",
    "        # if(n_week_day == 6):\n",
    "        #     n_week_day = 0\n",
    "        # else:\n",
    "        #     n_week_day +=1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Zadanie 4\n",
    "\n",
    "loaded_data = []\n",
    "\n",
    "# with open(\"GEFCOM.txt\", \"r\") as file:\n",
    "with open(\"NPdata_2013-2016.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        strintIO_line = StringIO(line)\n",
    "        npLine = np.loadtxt(strintIO_line)\n",
    "        loaded_data.append(npLine)\n",
    "\n",
    "loaded_data = np.array(loaded_data)\n",
    "\n",
    "data_361_1082 = loaded_data[361*24:1082*24,2]\n",
    "\n",
    "# Naive forecasting\n",
    "data_361_1082_naive_pred = np.zeros((np.shape(data_361_1082)))\n",
    "data_361_1082_naive_pred[0:24] = data_361_1082[0:24]\n",
    "\n",
    "for i in range(24,17304):\n",
    "    data_361_1082_naive_pred[i] = data_361_1082[i-24]\n",
    "\n",
    "# HW\n",
    "\n",
    "s = 4\n",
    "alpha = 0.1\n",
    "beta = 0.1\n",
    "gamma = 0.1\n",
    "\n",
    "L = np.zeros(17304)\n",
    "T = L.copy()\n",
    "S = L.copy()\n",
    "fx = L.copy()\n",
    "# Set initial values of L, T and S\n",
    "L[s-1] = np.sum(data_361_1082[:s]) / s\n",
    "T[s-1] = np.sum(data_361_1082[s:2*s] - data_361_1082[:s]) / (s ** 2)\n",
    "S[:s] = data_361_1082[:s] - L[s-1]\n",
    "\n",
    "# Iterate to compute L(t), T(t), S(t) and FX(t)\n",
    "for t in range(s, len(data_361_1082)-1):\n",
    "    L[t] = alpha * (data_361_1082[t] - S[t-s]) + (1 - alpha) * (L[t-1] + T[t-1])\n",
    "    T[t] = beta * (L[t] - L[t-1]) + (1 - beta) * T[t-1]\n",
    "    S[t] = gamma * (data_361_1082[t] - L[t]) + (1 - gamma) * S[t-s]\n",
    "    fx[t+1] = L[t] + T[t] + S[t - s + 1]\n",
    "\n",
    "def dmtest(e1, e2, h=1, lossf='AE'):\n",
    "    e1 = np.array(e1)\n",
    "    e2 = np.array(e2)\n",
    "    T = len(e1)\n",
    "    # AE: r=1\n",
    "    if lossf == 'AE':\n",
    "        d = np.abs(e1) - np.abs(e2)\n",
    "    # AE: r=2\n",
    "    else: # lossf == 'SE'\n",
    "        d = e1**2 - e2**2\n",
    "    dMean = np.mean(d)\n",
    "    gamma0 = np.var(d)\n",
    "    if h > 1:\n",
    "        raise NotImplementedError()\n",
    "    else:\n",
    "        varD = gamma0\n",
    "\n",
    "    DM = dMean / np.sqrt((1 / T) * varD)\n",
    "    return DM\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stałe okno (zad 5)\n",
    "\n",
    "# data = np.loadtxt('GEFCOM.txt')\n",
    "data = np.loadtxt('NPdata_2013-2016.txt')\n",
    "startd = 0   # First day of the calibration window (startd from Matlab minus 1)\n",
    "endd = 360   # First day to forecast (equal to endd from Matlab)\n",
    "Ndays = 722  # user provided number of days to be predicted\n",
    "             # (max is 722 for GEFCom with endd=360)\n",
    "\n",
    "loc_index = 0\n",
    "save_beta = np.zeros((24,12))\n",
    "\n",
    "# naive, arx, narx or narx_mc\n",
    "forecast_type = 'arx'\n",
    "\n",
    "# Estimate and compute forecasts of the ARX model\n",
    "res = epf_arx(data[:, :4], Ndays, startd, endd, forecast_type,loc_index,save_beta)\n",
    "\n",
    "res_arx_stale_okno = res[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dmtest(e1, e2, h=1, lossf='AE'):\n",
    "    e1 = np.array(e1)\n",
    "    e2 = np.array(e2)\n",
    "    T = len(e1)\n",
    "    if lossf == 'AE':\n",
    "        d = np.abs(e1) - np.abs(e2)\n",
    "    else: # lossf == 'SE'\n",
    "        d = e1**2 - e2**2\n",
    "    dMean = np.mean(d)\n",
    "    gamma0 = np.var(d)\n",
    "    if h > 1:\n",
    "        raise NotImplementedError()\n",
    "    else:\n",
    "        varD = gamma0\n",
    "\n",
    "    DM = dMean / np.sqrt((1 / T) * varD)\n",
    "    return DM\n",
    "\n",
    "def forecast_arx(DATA):\n",
    "    # DATA: 8-column matrix (date, hour, price, load forecast, Sat, Sun, Mon dummy, p_min)\n",
    "    # Select data to be used\n",
    "    # print(DATA[-1, :])\n",
    "    price = DATA[:-1, 2]             # For day d (d-1, ...)\n",
    "    price_min = DATA[:-1, 11]         # For day d\n",
    "    Dummies = DATA[1:, 4:11]          # Dummies for day d+1\n",
    "    loadr = DATA[1:, 3]              # Load for day d+1\n",
    "\n",
    "    # Take logarithms\n",
    "    price = np.log(price)\n",
    "    mc = np.mean(price)\n",
    "    price -= mc                      # Remove mean(price)\n",
    "    price_min = np.log(price_min)\n",
    "    price_min -= np.mean(price_min)  # Remove mean(price)\n",
    "    loadr = np.log(loadr)\n",
    "\n",
    "    # Calibrate the ARX model\n",
    "    y = price[7:]                    # For day d, d-1, ...\n",
    "    # Define explanatory variables for calibration\n",
    "    # without intercept\n",
    "    X = np.vstack([price[6:-1], price[5:-2], price[:-7], price_min[6:-1],\n",
    "                   loadr[6:-1], Dummies[6:-1, 0], Dummies[6:-1, 1], Dummies[6:-1, 2], Dummies[6:-1, 3], Dummies[6:-1, 4], Dummies[6:-1, 5], Dummies[6:-1, 6]]).T\n",
    "    # with intercept\n",
    "    # X = np.vstack([np.ones(len(y)), price[6:-1], price[5:-2], price[:-7], price_min[6:-1],\n",
    "    #                loadr[6:-1], Dummies[6:-1, 0], Dummies[6:-1, 1], Dummies[6:-1, 2]]).T\n",
    "    # Define explanatory variables for day d+1\n",
    "    # without intercept\n",
    "    X_fut = np.hstack([price[-1], price[-2], price[-7], price_min[-1],\n",
    "                    loadr[-1], Dummies[-1, 0], Dummies[-1, 1], Dummies[-1, 2], Dummies[-1, 3], Dummies[-1, 4], Dummies[-1, 5], Dummies[-1, 6]])\n",
    "    # with intercept\n",
    "    # X_fut = np.hstack([[1], price[-1], price[-2], price[-7], price_min[-1],\n",
    "    #                    loadr[-1], Dummies[-1, 0], Dummies[-1, 1], Dummies[-1, 2]])\n",
    "    beta = np.linalg.lstsq(X, y, rcond=None)[0]  # Estimate the ARX model\n",
    "    prog = np.dot(beta, X_fut)                   # Compute a step-ahead forecast\n",
    "    return np.exp(prog + mc)                     # Convert to price level\n",
    "\n",
    "def forecast_narx(DATA):\n",
    "    import keras\n",
    "    from keras.layers import Input, Dense\n",
    "    from keras.models import Model\n",
    "    from keras.callbacks import EarlyStopping\n",
    "    # DATA: 8-column matrix (date, hour, price, load forecast, Sat, Sun, Mon dummy, p_min)\n",
    "    # Select data to be used\n",
    "    # print(DATA[-1, :])\n",
    "    price = DATA[:-1, 2]             # For day d (d-1, ...)\n",
    "    price_min = DATA[:-1, 7]         # For day d\n",
    "    Dummies = DATA[1:, 4:7]          # Dummies for day d+1\n",
    "    loadr = DATA[1:, 3]              # Load for day d+1\n",
    "\n",
    "    # Take logarithms\n",
    "    price = np.log(price)\n",
    "    mc = np.mean(price)\n",
    "    price -= mc                      # Remove mean(price)\n",
    "    price_min = np.log(price_min)\n",
    "    price_min -= np.mean(price_min)  # Remove mean(price)\n",
    "    loadr = np.log(loadr)\n",
    "\n",
    "    # Calibrate the ARX model\n",
    "    y = price[7:]                    # For day d, d-1, ...\n",
    "    # Define explanatory variables for calibration\n",
    "    X = np.vstack([price[6:-1], price[5:-2], price[:-7], price_min[6:-1],\n",
    "                   loadr[6:-1], Dummies[6:-1, 0], Dummies[6:-1, 1], Dummies[6:-1, 2]]).T\n",
    "    # Define explanatory variables for day d+1\n",
    "    X_fut = np.hstack([price[-1], price[-2], price[-7], price_min[-1],\n",
    "                       loadr[-1], Dummies[-1, 0], Dummies[-1, 1], Dummies[-1, 2]])\n",
    "\n",
    "    # Define Neural Network model\n",
    "    inputs = Input(shape=(X.shape[1], ))                  # Input layer\n",
    "    hidden = Dense(units=20, activation='sigmoid')(inputs)# Hidden layer (20 neurons)\n",
    "    outputs = Dense(units=1, activation='linear')(hidden) # Output layer\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    # callbacks = [EarlyStopping(patience=20, restore_best_weights=True)]\n",
    "    callbacks = []\n",
    "    model.compile(loss='MAE', optimizer='ADAM')           # Compile model\n",
    "    model.fit(X, y, batch_size=64, epochs=500, verbose=0, # Fit to data\n",
    "              validation_split=.0, shuffle=False, callbacks=callbacks)\n",
    "    prog = model.predict(np.array(X_fut, ndmin=2))        # Compute a step-ahead forecast\n",
    "\n",
    "    return np.exp(prog + mc)                     # Convert to price level\n",
    "\n",
    "def forecast_naive(DATA):\n",
    "    if np.sum(DATA[-1, 4:7]) > 0:\n",
    "        return DATA[-8, 2]\n",
    "    return DATA[-2, 2]\n",
    "\n",
    "import numpy as np\n",
    "from calendar import weekday\n",
    "from time import time as t\n",
    "\n",
    "def task(argtup):\n",
    "    '''Helper function for multi-core NARX'''\n",
    "    data, startd, endd, j, hour = argtup\n",
    "    data_h = data[hour::24, :]\n",
    "    ts = t()\n",
    "    task_output = forecast_narx(data_h[startd + j:endd + j + 1, :])\n",
    "    print(f'{j}\\t{hour}\\t{t() - ts}')\n",
    "    return task_output \n",
    "\n",
    "def epf_arx(data, Ndays, startd, endd, forecast_type='naive'):\n",
    "    if forecast_type.lower() == 'narx':      # forecst_narx imports additional libraries, importing\n",
    "        print(\":)\")\n",
    "        # from forecast import forecast_narx   # here ensures that they are not needed for ARX or naive\n",
    "    elif forecast_type.lower() == 'narx_mc': # multi-core variant\n",
    "        from multiprocessing import Pool\n",
    "    # DATA:   4-column matrix (date, hour, price, load forecast)\n",
    "    # RESULT: 4-column matrix (date, hour, price, forecasted price)\n",
    "    first_day = str(int(data[0, 0]))\n",
    "    first_day = (int(e) for e in (first_day[:4], first_day[4:6], first_day[6:]))\n",
    "    i = weekday(*first_day) # Weekday of starting day: 0 - Monday, ..., 6 - Sunday\n",
    "    N = len(data) // 24\n",
    "    data = np.hstack([data, np.zeros((N*24, 9))]) # Append 'data' matrix with daily dummies & p_min\n",
    "    for j in range(N):\n",
    "        if i % 7 == 5:\n",
    "            data[24*j:24*(j+1), 4] = 1 # Saturday dummy in 5th (index 4) column\n",
    "        elif i % 7 == 6:\n",
    "            data[24*j:24*(j+1), 5] = 1 # Sunday dummy in 6th column\n",
    "        elif i % 7 == 0:\n",
    "            data[24*j:24*(j+1), 6] = 1 # Monday dummy in 7th column\n",
    "        elif i % 7 == 1:\n",
    "            data[24*j:24*(j+1), 7] = 1 # wtorek\n",
    "        elif i % 7 == 2:\n",
    "            data[24*j:24*(j+1), 8] = 1 # sroda\n",
    "        elif i % 7 == 3:\n",
    "            data[24*j:24*(j+1), 9] = 1 # czwartek\n",
    "        elif i % 7 == 4:\n",
    "            data[24*j:24*(j+1), 10] = 1 # piatek\n",
    "\n",
    "        '''\n",
    "        # Dummies dla pozostałych dni\n",
    "        '''\n",
    "        i += 1\n",
    "        data[24*j:24*(j+1), 11] = np.min(data[24*j:24*(j+1), 2]) # p_min in 8th column\n",
    "    result = np.zeros((Ndays * 24, 4)) # Initialize `result` matrix\n",
    "    result[:, :3] = data[endd*24:(endd + Ndays) * 24, :3]\n",
    "    if forecast_type.lower() == 'narx_mc': # multi-core invocation of NARX model\n",
    "        argtups = [(data, startd, endd, j, h) for j in range(Ndays) for h in range(24)]\n",
    "        with Pool() as pool:   # Pool(N) uses N simultaneous processes\n",
    "            res = pool.map(task, argtups)\n",
    "        result[:, 3] = res\n",
    "        return result\n",
    "    for j in range(Ndays):     # For all days ...\n",
    "        for hour in range(24): # ... compute 1-day ahead forecasts for each hour\n",
    "            data_h = data[hour::24, :]\n",
    "            # Compute forecasts for the hour\n",
    "            if forecast_type.lower() == 'narx':\n",
    "                ts = t()\n",
    "                result[j * 24 + hour, 3] = forecast_narx(data_h[startd + j:endd + j + 1, :])\n",
    "                print(f'{j}\\t{hour}\\t{t() - ts}')\n",
    "            elif forecast_type.lower() == 'arx':\n",
    "                result[j * 24 + hour, 3] = forecast_arx(data_h[startd:endd + j + 1, :])\n",
    "            elif forecast_type.lower() == 'naive':\n",
    "                result[j * 24 + hour, 3] = forecast_naive(data_h[startd + j:endd + j + 1, :])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zadanie 6 rozszerzane okno\n",
    "# data = np.loadtxt('GEFCOM.txt')\n",
    "data = np.loadtxt('NPdata_2013-2016.txt')\n",
    "startd = 0   # First day of the calibration window (startd from Matlab minus 1)\n",
    "endd = 360   # First day to forecast (equal to endd from Matlab)\n",
    "Ndays = 722  # user provided number of days to be predicted\n",
    "             # (max is 722 for GEFCom with endd=360)\n",
    "\n",
    "# naive, arx, narx or narx_mc\n",
    "forecast_type = 'arx'\n",
    "\n",
    "# Estimate and compute forecasts of the ARX model\n",
    "res = epf_arx(data[:, :4], Ndays, startd, endd, forecast_type)\n",
    "res_arx_rozszerzane_okno = res[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Metoda ARX rozszerzane okno vs WH dla 8 rano: 6.95139992813106\nMetoda ARX rozszerzane okno vs WH dla 8 rano p value: 1.8084422848119175e-12\nMetoda ARX rozszerzane okno vs WH dla 24h: 6.021033301531873\nMetoda ARX rozszerzane okno vs WH dla 24h p value: 8.665355100134775e-10\nMetoda HW vs ARX rozszerzane okno dla 8 rano: -3.5253972015815864\nMetoda HW vs ARX rozszerzane okno dla 8 rano p-value: 0.9997885758726905\nMetoda HW vs ARX rozszerzane okno dla 24h: -6.192178701124291\nMetoda HW vs ARX rozszerzane okno dla 24h p-value: 0.9999999997033089\n"
     ]
    }
   ],
   "source": [
    "# WH vs ARX ze rozszerzonym dniowym oknem\n",
    "rv = norm()\n",
    "\n",
    "# rozszerzane_okno vs HW\n",
    "temp_res=res_arx_rozszerzane_okno[2*s+8::24]\n",
    "rozszerzane_okno_hw_DM_r_1 = dmtest(res_arx_rozszerzane_okno[2*s:17288], fx[2*s:17288])\n",
    "rozszerzane_okno_hw_DM_r_2 = dmtest(temp_res[:721], fx[2*s+8::24], lossf=\"R2\")\n",
    "\n",
    "rv = norm()\n",
    "\n",
    "print(\"Metoda ARX rozszerzane okno vs WH dla 8 rano: \" + str(stale_okno_hw_DM_r_2))\n",
    "print(\"Metoda ARX rozszerzane okno vs WH dla 8 rano p value: \" + str(1 - rv.cdf(stale_okno_hw_DM_r_2)))\n",
    "print(\"Metoda ARX rozszerzane okno vs WH dla 24h: \" + str(rozszerzane_okno_hw_DM_r_1))\n",
    "print(\"Metoda ARX rozszerzane okno vs WH dla 24h p value: \" + str(1 - rv.cdf(rozszerzane_okno_hw_DM_r_1)))\n",
    "\n",
    "# HW vs rozszerzane_okno\n",
    "temp_res = res_arx_rozszerzane_okno[2*s+8::24]\n",
    "hw_rozszerzane_okno_DM_r_1 = dmtest(fx[2*s:2*s+17288], res_arx_rozszerzane_okno[2*s:17296])\n",
    "hw_rozszerzane_okno_DM_r_2 = dmtest(fx[2*s+8::24],temp_res[:721],  lossf=\"R2\")\n",
    "\n",
    "print(\"Metoda HW vs ARX rozszerzane okno dla 8 rano: \" + str(hw_rozszerzane_okno_DM_r_2))\n",
    "print(\"Metoda HW vs ARX rozszerzane okno dla 8 rano p-value: \" + str(1-rv.cdf(hw_rozszerzane_okno_DM_r_2)))\n",
    "print(\"Metoda HW vs ARX rozszerzane okno dla 24h: \" + str(hw_rozszerzane_okno_DM_r_1))\n",
    "print(\"Metoda HW vs ARX rozszerzane okno dla 24h p-value: \" + str(1-rv.cdf(hw_rozszerzane_okno_DM_r_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Metoda ARX rozszerzane okno vs naive dla 8 rano: 1.0374939283973685\nMetoda ARX rozszerzane okno vs naive dla 8 rano p value: 0.1497528619437043\nMetoda ARX rozszerzane okno vs naive dla 24h: 10.41841790670619\nMetoda ARX rozszerzane okno vs naive dla 24h p value: 0.0\nMetoda naive vs ARX rozszerzane okno dla 8 rano: -1.0374939283973685\nMetoda naive vs ARX rozszerzane okno dla 8 rano p-value: 0.8502471380562957\nMetoda naive vs ARX rozszerzane okno dla 24h: -10.41841790670619\nMetoda naive vs ARX rozszerzane okno dla 24h p-value: 1.0\n"
     ]
    }
   ],
   "source": [
    "# naive vs ARX ze rozszerzonym dniowym oknem\n",
    "rv = norm()\n",
    "\n",
    "# rozszerzane_okno vs naive\n",
    "temp_res=res_arx_rozszerzane_okno[8::24]\n",
    "rozszerzane_okno_naive_DM_r_1 = dmtest(res_arx_rozszerzane_okno[:17304],data_361_1082_naive_pred)\n",
    "rozszerzane_okno_naive_DM_r_2 = dmtest(temp_res[:721], data_361_1082_naive_pred[8::24], lossf=\"R2\")\n",
    "\n",
    "rv = norm()\n",
    "\n",
    "print(\"Metoda ARX rozszerzane okno vs naive dla 8 rano: \" + str(rozszerzane_okno_naive_DM_r_2))\n",
    "print(\"Metoda ARX rozszerzane okno vs naive dla 8 rano p value: \" + str(1 - rv.cdf(rozszerzane_okno_naive_DM_r_2)))\n",
    "print(\"Metoda ARX rozszerzane okno vs naive dla 24h: \" + str(rozszerzane_okno_naive_DM_r_1))\n",
    "print(\"Metoda ARX rozszerzane okno vs naive dla 24h p value: \" + str(1 - rv.cdf(rozszerzane_okno_naive_DM_r_1)))\n",
    "\n",
    "# naive vs rozszerzane_okno\n",
    "# temp_res = res_arx_rozszerzane_okno[2*s+8::24]\n",
    "naive_rozszerzane_okno_DM_r_1 = dmtest(data_361_1082_naive_pred, res_arx_rozszerzane_okno[:17304])\n",
    "naive_rozszerzane_okno_DM_r_2 = dmtest(data_361_1082_naive_pred[8::24],temp_res[:721],  lossf=\"R2\")\n",
    "\n",
    "print(\"Metoda naive vs ARX rozszerzane okno dla 8 rano: \" + str(naive_rozszerzane_okno_DM_r_2))\n",
    "print(\"Metoda naive vs ARX rozszerzane okno dla 8 rano p-value: \" + str(1-rv.cdf(naive_rozszerzane_okno_DM_r_2)))\n",
    "print(\"Metoda naive vs ARX rozszerzane okno dla 24h: \" + str(naive_rozszerzane_okno_DM_r_1))\n",
    "print(\"Metoda naive vs ARX rozszerzane okno dla 24h p-value: \" + str(1-rv.cdf(naive_rozszerzane_okno_DM_r_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Metoda ARX rozszerzane okno vs stale okno dla 8 rano: 9.738766071344145\nMetoda ARX rozszerzane okno vs stale okno dla 8 rano p value: 0.0\nMetoda ARX rozszerzane okno vs stale okno dla 24h: 9.076333292830443\nMetoda ARX rozszerzane okno vs stale okno dla 24h p value: 0.0\nMetoda stale okno vs ARX rozszerzane okno dla 8 rano: -9.738766071344145\nMetoda stale okno vs ARX rozszerzane okno dla 8 rano p-value: 1.0\nMetoda stale okno vs ARX rozszerzane okno dla 24h: -9.076333292830443\nMetoda stale okno vs ARX rozszerzane okno dla 24h p-value: 1.0\n"
     ]
    }
   ],
   "source": [
    "# stale okno vs ARX ze rozszerzonym dniowym oknem\n",
    "rv = norm()\n",
    "\n",
    "# rozszerzane_okno vs stale_okno\n",
    "temp_res=res_arx_rozszerzane_okno[8::24]\n",
    "rozszerzane_okno_stale_okno_DM_r_1 = dmtest(res_arx_rozszerzane_okno,res_arx_stale_okno)\n",
    "rozszerzane_okno_stale_okno_DM_r_2 = dmtest(res_arx_rozszerzane_okno[8::24], res_arx_stale_okno[8::24], lossf=\"R2\")\n",
    "\n",
    "rv = norm()\n",
    "\n",
    "print(\"Metoda ARX rozszerzane okno vs stale okno dla 8 rano: \" + str(rozszerzane_okno_stale_okno_DM_r_2))\n",
    "print(\"Metoda ARX rozszerzane okno vs stale okno dla 8 rano p value: \" + str(1 - rv.cdf(rozszerzane_okno_stale_okno_DM_r_2)))\n",
    "print(\"Metoda ARX rozszerzane okno vs stale okno dla 24h: \" + str(rozszerzane_okno_stale_okno_DM_r_1))\n",
    "print(\"Metoda ARX rozszerzane okno vs stale okno dla 24h p value: \" + str(1 - rv.cdf(rozszerzane_okno_stale_okno_DM_r_1)))\n",
    "\n",
    "# stale okno vs rozszerzane_okno\n",
    "# temp_res = res_arx_rozszerzane_okno[2*s+8::24]\n",
    "stale_okno_rozszerzane_okno_DM_r_1 = dmtest(res_arx_stale_okno, res_arx_rozszerzane_okno)\n",
    "stale_okno_rozszerzane_okno_DM_r_2 = dmtest(res_arx_stale_okno[8::24],res_arx_rozszerzane_okno[8::24],  lossf=\"R2\")\n",
    "\n",
    "print(\"Metoda stale okno vs ARX rozszerzane okno dla 8 rano: \" + str(stale_okno_rozszerzane_okno_DM_r_2))\n",
    "print(\"Metoda stale okno vs ARX rozszerzane okno dla 8 rano p-value: \" + str(1-rv.cdf(stale_okno_rozszerzane_okno_DM_r_2)))\n",
    "print(\"Metoda stale okno vs ARX rozszerzane okno dla 24h: \" + str(stale_okno_rozszerzane_okno_DM_r_1))\n",
    "print(\"Metoda stale okno vs ARX rozszerzane okno dla 24h p-value: \" + str(1-rv.cdf(stale_okno_rozszerzane_okno_DM_r_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Metoda ARX stale okno vs WH dla 8 rano: 3.5253972015815864\n",
      "Metoda ARX stale okno vs WH dla 8 rano p value: 0.00021142412730945637\n",
      "Metoda ARX stale okno vs WH dla 24h: 6.021033301531873\n",
      "Metoda ARX stale okno vs WH dla 24h p value: 8.665355100134775e-10\n",
      "Metoda HW vs ARX stale okno dla 8 rano: -3.5253972015815864\n",
      "Metoda HW vs ARX stale okno dla 8 rano p-value: 0.9997885758726905\n",
      "Metoda HW vs ARX stale okno dla 24h: -6.192178701124291\n",
      "Metoda HW vs ARX stale okno dla 24h p-value: 0.9999999997033089\n"
     ]
    }
   ],
   "source": [
    "# WH vs ARX ze stalym 360 dniowym oknem\n",
    "\n",
    "rv = norm()\n",
    "\n",
    "# stale_okno vs HW\n",
    "temp_res=res[2*s+8::24,3]\n",
    "stale_okno_hw_DM_r_1 = dmtest(res[2*s:17288,3], fx[2*s:17288])\n",
    "stale_okno_hw_DM_r_2 = dmtest(temp_res[:721], fx[2*s+8::24], lossf=\"R2\")\n",
    "\n",
    "rv = norm()\n",
    "\n",
    "print(\"Metoda ARX stale okno vs WH dla 8 rano: \" + str(stale_okno_hw_DM_r_2))\n",
    "print(\"Metoda ARX stale okno vs WH dla 8 rano p value: \" + str(1 - rv.cdf(stale_okno_hw_DM_r_2)))\n",
    "print(\"Metoda ARX stale okno vs WH dla 24h: \" + str(stale_okno_hw_DM_r_1))\n",
    "print(\"Metoda ARX stale okno vs WH dla 24h p value: \" + str(1 - rv.cdf(stale_okno_hw_DM_r_1)))\n",
    "\n",
    "# HW vs stale_okno\n",
    "temp_res = res[2*s+8::24,3]\n",
    "hw_stale_okno_DM_r_1 = dmtest(fx[2*s:2*s+17288], res[2*s:17296,3])\n",
    "hw_stale_okno_DM_r_2 = dmtest(fx[2*s+8::24],temp_res[:721],  lossf=\"R2\")\n",
    "\n",
    "print(\"Metoda HW vs ARX stale okno dla 8 rano: \" + str(hw_stale_okno_DM_r_2))\n",
    "print(\"Metoda HW vs ARX stale okno dla 8 rano p-value: \" + str(1-rv.cdf(hw_stale_okno_DM_r_2)))\n",
    "print(\"Metoda HW vs ARX stale okno dla 24h: \" + str(hw_stale_okno_DM_r_1))\n",
    "print(\"Metoda HW vs ARX stale okno dla 24h p-value: \" + str(1-rv.cdf(hw_stale_okno_DM_r_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Metoda naive vs ARX stale okno dla 8 rano: 0.4085817930969391\n",
      "Metoda naive vs ARX stale okno dla 8 rano p value: 0.341423297143721\n",
      "Metoda naive vs ARX stale okno dla 24h: -10.41841790670619\n",
      "Metoda naive vs ARX stale okno dla 24h p value: 1.0\n",
      "Metoda HW vs naive dla 8 rano: -0.4085817930969391\n",
      "Metoda HW vs naive dla 8 rano p-value: 0.658576702856279\n",
      "Metoda HW vs naive dla 24h: 10.41841790670619\n",
      "Metoda HW vs naive dla 24h p-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Naive vs ARX ze stalym 360 dniowym oknem\n",
    "\n",
    "rv = norm()\n",
    "\n",
    "naive_stale_okno_r1 = dmtest(data_361_1082_naive_pred,res[:17304,3])\n",
    "naive_stale_okno_r2 = dmtest(data_361_1082_naive_pred[8::24], dane_arx_8_rano[:721],lossf=\"R2\")\n",
    "print(\"Metoda naive vs ARX stale okno dla 8 rano: \" + str(naive_stale_okno_r2))\n",
    "print(\"Metoda naive vs ARX stale okno dla 8 rano p value: \" + str(1 - rv.cdf(naive_stale_okno_r2)))\n",
    "print(\"Metoda naive vs ARX stale okno dla 24h: \" + str(naive_stale_okno_r1))\n",
    "print(\"Metoda naive vs ARX stale okno dla 24h p value: \" + str(1 - rv.cdf(naive_stale_okno_r1)))\n",
    "\n",
    "stale_okno_naive_r1 = dmtest(res[:17304,3], data_361_1082_naive_pred)\n",
    "\n",
    "stale_okno_naive_r2 = dmtest(dane_arx_8_rano[:721], data_361_1082_naive_pred[8:17304:24], lossf=\"R2\")\n",
    "print(\"Metoda HW vs naive dla 8 rano: \" + str(stale_okno_naive_r2))\n",
    "print(\"Metoda HW vs naive dla 8 rano p-value: \" + str(1-rv.cdf(stale_okno_naive_r2)))\n",
    "print(\"Metoda HW vs naive dla 24h: \" + str(stale_okno_naive_r1))\n",
    "print(\"Metoda HW vs naive dla 24h p-value: \" + str(1-rv.cdf(stale_okno_naive_r1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Metoda naive vs HW dla 8 rano: 3.0751912907866354\nMetoda naive vs HW dla 8 rano p value: 0.0010518379086487117\nMetoda naive vs HW dla 24h: 0.2648701506748458\nMetoda naive vs HW dla 24h p value: 0.39555474680520375\nMetoda HW vs naive dla 8 rano: -3.0751912907866354\nMetoda HW vs naive dla 8 rano p-value: 0.9989481620913513\nMetoda HW vs naive dla 24h: -0.2648701506748458\nMetoda HW vs naive dla 24h p-value: 0.6044452531947963\n"
     ]
    }
   ],
   "source": [
    "# Naive vs HW\n",
    "\n",
    "naive_hw_DM_r_1 = dmtest(data_361_1082_naive_pred[2*s:], fx[2*s:])\n",
    "naive_hw_DM_r_2 = dmtest(data_361_1082_naive_pred[2*s+8::24], fx[2*s+8::24], lossf=\"R2\")\n",
    "\n",
    "rv = norm()\n",
    "\n",
    "print(\"Metoda naive vs HW dla 8 rano: \" + str(naive_hw_DM_r_2))\n",
    "p_naive_hw_DM_r_2 = 1 - rv.cdf(naive_hw_DM_r_2)\n",
    "print(\"Metoda naive vs HW dla 8 rano p value: \" + str(p_naive_hw_DM_r_2))\n",
    "print(\"Metoda naive vs HW dla 24h: \" + str(naive_hw_DM_r_1))\n",
    "p_naive_hw_DM_r_1 = 1 - rv.cdf(naive_hw_DM_r_1)\n",
    "print(\"Metoda naive vs HW dla 24h p value: \" + str(p_naive_hw_DM_r_1))\n",
    "\n",
    "# HW vs Naive\n",
    "\n",
    "hw_naive_DM_r_1 = dmtest(fx[2*s:], data_361_1082_naive_pred[2*s:])\n",
    "hw_naive_DM_r_2 = dmtest(fx[2*s+8::24],data_361_1082_naive_pred[2*s+8::24],  lossf=\"R2\")\n",
    "\n",
    "print(\"Metoda HW vs naive dla 8 rano: \" + str(hw_naive_DM_r_2))\n",
    "print(\"Metoda HW vs naive dla 8 rano p-value: \" + str(1-rv.cdf(hw_naive_DM_r_2)))\n",
    "print(\"Metoda HW vs naive dla 24h: \" + str(hw_naive_DM_r_1))\n",
    "print(\"Metoda HW vs naive dla 24h p-value: \" + str(1-rv.cdf(hw_naive_DM_r_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "get_ipython().magic('reset -sf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}